---
title: "Projet SICCS Montreal 2023 de Shamsi Soltani"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  warning = TRUE, # show warnings
  message = TRUE, # show messages
  error = TRUE, # do not interrupt generation in case of errors,
  echo = TRUE  # show R code
)
library(pacman)
p_load(knitr, 
       tidyverse, tidytext, 
       textdata, tm, 
       maps, SnowballC, 
       wordcloud, topicmodels, repoRter.nih)

knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 60), tidy = TRUE)
```

*Run* = *Cmd+Shift+Enter*. *Insert Chunk* = *Cmd+Option+I*

```{r}
#exploring repoRter.nih

#define fields you want 
data("nih_fields") 

fields <- nih_fields %>%
  filter(response_name %in% 
    c("appl_id", "terms", "activity_code", "project_title", "fiscal_year", "award_amount", "is_active", "project_start_date", "abstract_text","program_officers", "activity_type" #, "organization", "organization_type"
      )) %>% pull(include_name)


# req <- make_req(criteria = list(fiscal_years = 2013:2023 #more recent active awards will be included
#                                 #, include_active_projects = TRUE,
#                                 ),
#                 include_fields = fields, limit = 50, message = FALSE)
# grants %>% glimpse(width = getOption("cli.width"))


req <- make_req(criteria = list(advanced_text_search 
                    = list(operator = "advanced",
                    search_field = c("terms", "abstract", "projecttitle"),
                    search_text = "(suicide) OR \"self-directed violence\""),
             activity_codes = 'F31',
             fiscal_years = 2012:2023
             ),
      include_fields = fields )

grants <- get_nih_data(query = req, max_pages = 1, flatten_result=TRUE)
    #remove max pages once query final if seeking more than 500 recs

table(grants$activity_code) 
  #N=225 F31 funded apps in last decade with suicide or self-directed violence as a title, narrative, or key word; 340 total in database
```
```{r text processing}
# Create corpus
corpus = Corpus(VectorSource(grants$abstract_text))

#Conversion to Lowercase

corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, tolower)

#Removing Punctuation
corpus = tm_map(corpus, removePunctuation)

#Remove stopwords
corpus = tm_map(corpus, removeWords, c("project", "summary", stopwords("english")))

# Stemming
corpus = tm_map(corpus, stemDocument)

# Eliminate white spaces
corpus = tm_map(corpus, stripWhitespace)

# Look at first instance of corpus
corpus[[1]][1]

#Document term matrix
DTM <- TermDocumentMatrix(corpus)
mat <- as.matrix(DTM)
f <- sort(rowSums(mat),decreasing=TRUE)
dat <- data.frame(word = names(f),freq=f)

head(dat, 5)
```
```{r wordcloud}
#Text mining packages
p_load(tm, SnowballC, "wordcloud","RColorBrewer")
set.seed(100)

wordcloud(words = dat$word, freq = dat$freq, random.order=TRUE)
```

```{r}
p_load(tidyverse,magrittr,rvest)
#setwd('/Users/ssoltani/Desktop/PhD coursework/Cours_SICSS_Montreal/grant funding project')
rawHTML <- read_html("./00.Data/CIHR_suicide_research.html")

page_section <- html_node(rawHTML, css = '#frmSearchLocation > table > tbody > tr:nth-child(5) td')

#page_section <- html_node(rawHTML, xpath = '//br+//table//td')

file <- html_text(page_section)

#one method to break up text into different cells
require(data.table)
o = fread(file, sep = '\n', header = T)

  #test 
  #o = c('zy', 'x    y', '')

#trim whitespace
o$`Search Results` = str_trim(o$`Search Results`)

#drop empty rows
drop_list = o$`Search Results`==""
o <- o[!drop_list, ]

#drop rows saying "Details..."
drop_list = o$`Search Results`== "Details..."
o <- o[!drop_list, ]

#some grant dates are in a 3-row format; merge when this is the case
  #e.g. 21
        #to
        #22
  # and not: 2023-24
o$merge_list = o$`Search Results`== "to"
  #sum(merge_list) #381
```

```{r}
library(tidyverse)

#flag consecutive rows which need merging
p = o %>% 
  mutate(merge_rows=
           ifelse(merge_list==T ,
              paste(row_number()-1, row_number()+1, sep = ":"),
              NA),
        merge_start =
           ifelse(merge_list==T,
              paste(row_number()-1)
              ,NA)
         ) %>% 
  filter(merge_list==T)

### not working
##as.data.frame(p)
o[p[[4]],]

paste(o[[p$merge_rows]]

  mutate(concated_column = o[merge_rows,])

rbind(p, row3 = apply(p, 2, paste0, collapse = "-"))
```

```{r}

input <- data_frame(text = file)
input

p_load(dplyr, lubridate)
df <- matrix(input, ncol = 7, byrow = TRUE) %>% 
  as_tibble() %>% 
  mutate(V1 = mdy(V1), V2 = as.numeric(V2))



data$text
data <-
  data %>% 
  separate(text, into = c("text1", "text2", "text3", "text4", "text5", 
                          "text6", "text7", "text8", "text9", "text10"), sep = "Back to text")
```
