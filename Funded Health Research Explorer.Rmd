---
title: "Projet SICCS Montreal 2023 de Shamsi Soltani"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  warning = TRUE, # show warnings
  message = TRUE, # show messages
  error = TRUE, # do not interrupt generation in case of errors,
  echo = TRUE  # show R code
)
library(pacman)
p_load(knitr, 
       tidyverse, tidytext, 
       textdata, tm, 
       maps, SnowballC, 
       wordcloud, topicmodels, repoRter.nih)

knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 60), tidy = TRUE)
```

*Run* = *Cmd+Shift+Enter*. *Insert Chunk* = *Cmd+Option+I*

#1.0 Use Reporter NIH package

##1.1 Testing package with small dataset

```{r}
#exploring repoRter.nih

#define fields you want 
data("nih_fields") 

fields <- nih_fields %>%
  filter(response_name %in% 
    c("appl_id", "terms", "activity_code", "project_title", "fiscal_year", "award_amount", "is_active", "project_start_date", "abstract_text","program_officers", "activity_type" #, "organization", "organization_type"
      )) %>% pull(include_name)


# req <- make_req(criteria = list(fiscal_years = 2013:2023 #more recent active awards will be included
#                                 #, include_active_projects = TRUE,
#                                 ),
#                 include_fields = fields, limit = 50, message = FALSE)
# grants %>% glimpse(width = getOption("cli.width"))


req <- make_req(criteria = list(advanced_text_search 
                    = list(operator = "advanced",
                    search_field = c("terms", "abstract", "projecttitle"),
                    search_text = "(suicide) OR \"self-directed violence\""),
             activity_codes = 'F31',
             fiscal_years = 2012:2023
             ),
      include_fields = fields )

grants <- get_nih_data(query = req, max_pages = 1, flatten_result=TRUE)
    #remove max pages once query final if seeking more than 500 recs

table(grants$activity_code) 
  #N=225 F31 funded apps in last decade with suicide or self-directed violence as a title, narrative, or key word; 340 total in database
```

##1.2 looking at small dataset using text analysis

```{r text processing}
# Create corpus
corpus = Corpus(VectorSource(grants$abstract_text))

#Conversion to Lowercase

corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, tolower)

#Removing Punctuation
corpus = tm_map(corpus, removePunctuation)

#Remove stopwords
corpus = tm_map(corpus, removeWords, c("project", "summary", stopwords("english")))

# Stemming
corpus = tm_map(corpus, stemDocument)

# Eliminate white spaces
corpus = tm_map(corpus, stripWhitespace)

# Look at first instance of corpus
corpus[[1]][1]

#Document term matrix
DTM <- TermDocumentMatrix(corpus)
mat <- as.matrix(DTM)
f <- sort(rowSums(mat),decreasing=TRUE)
dat <- data.frame(word = names(f),freq=f)

head(dat, 5)
```

##1.3 wordcloud

```{r wordcloud}
set.seed(100)
display.brewer.all(colorblindFriendly = TRUE)      # Show all color palettes

wordcloud(words = dat$word, freq = dat$freq, min.freq = 10,           max.words=500, random.order=F, scale=c(3,.25), rot.per=0.3
           , colors=brewer.pal(8, "Dark2"))

p_load(wordcloud2)
wordcloud2(dat,size = .8, minRotation = -pi/6, maxRotation = -pi/6, rotateRatio = 1)
```

##1.4 élargir la recherche à tous les fonds des NIH, parallèlement au code du CIHR (Voir "CIHR Data Import" de Leonard au GitHub)

CIHR fields include abstract = Abstract.Résumé, key = Key.Clé, name = Name.Nom, organization = OrgNm, province = ProvinceEN, country = CountryEN, year_comp = CompetitionYear.AnnéeDuConcours, year_fisc = FiscalYear.AnnéeFinancière, programID = ProgramIDProgramme, program_name = ProgramNameEN, funding_type = FundingTypeEN, science_areas = AreasOfScienceEN, research_class = ResearchClassEN, title = TitreApplicationTitle, keywords = Keywords.MotsClés

###1.4.1 define columns
```{r}

#define fields you want 
data("nih_fields") 

fields <- nih_fields %>%
  filter(response_name %in% 
    c("abstract_text", "project_serial_num", "contact_pi_name", "terms", "activity_code", "project_title", "fiscal_year", "award_amount", "is_active", "project_start_date", "activity_type",  "agency_ic_fundings", "cong_district", "spending_categories_desc", "full_foa"
      )) %>% pull(include_name)
```

abstract = "abstract_text", key = "project_serial_num" name = "contact_pi_name", \# possibly also "principal_investigators" organization = OrgNm, province = "cong_district", year_comp = "project_start_date", year_fisc = "fiscal_year", programID = ProgramIDProgramme, program_name = ProgramNameEN, funding_type = FundingTypeEN, science_areas = AreasOfScienceEN, research_class = ResearchClassEN, title = "project_title", keywords = "terms"

quels sont les mots qui indiquent les sciences sociales? J'ai: sociaux, sociales, qualitatives, qualitatif, qualitative, qualitatifs, sociale, social

en anglais: social, qualitative
#1.4.2 limit award types
```{r NIH grants types}
#activity codes ---> F, K grants for students, early career faculty (excludes institutional grants)
awards = c('F05', 'F30', 'F31', 'F32', 'F33', 
'F37', 'F38', 'F99', 'FI2', 'FM1',
#'R00',  'R01', 'R03', 'R13', 'R15', 'R16', 'R18', 
# 'R21','R24', 'R25', 'R28', 'R2F', 'R30', 
# 'R33', 'R34', 'R35', 'R36',  'R37', 'R38', 'R41', 'R42', 
# 'R43', 'R44', 'R49', 'R50',  'R55', 'R56', 'R61', 'R90', 
# 'RC1', 'RC2', 'RC3', 'RC4',  'RF1', 'RL1', 'RL2', 'RL5', 
# 'RL9', 'RM1', 'RS1', 
'K00', 'K01', 'K02', 'K05', 'K06', 
'K07', 'K08', 'K12', 'K14', 
'K18', 'K21', 'K22', 'K23', 
'K24', 'K25', 'K26', 'K30', 'K38', 'K43', 
'K76', 'K99', 'KD1', 'KL1', 'KL2', 'KM1' )
```

#1.4.3 create json for NIH API
```{r json}
#create json for NIH API
req <- make_req(criteria = list(advanced_text_search 
                    = list(operator = "advanced",
                    search_field = c("terms", "abstract", "projecttitle"),
                    search_text = "(social) OR (qualitative)"),
  fiscal_years = 2001:2023,
  activity_codes = awards
                              ), 
      include_fields = fields )
```
#1.4.4 retreive data
```{r}
grants <- get_nih_data(query = req, max_pages = 1, flatten_result=TRUE)


#remove max pages once query final if seeking more than 500 recs; 
#grants <- get_nih_data(query = req,  flatten_result=TRUE)
  #Note: API request fails after 15,000 records


```

#CIHR data

##strategie pas au courant-- voir le GH

```{r}
p_load(tidyverse,magrittr,rvest)
#setwd('/Users/ssoltani/Desktop/PhD coursework/Cours_SICSS_Montreal/grant funding project')
rawHTML <- read_html("./00.Data/CIHR_suicide_research.html")

page_section <- html_node(rawHTML, css = '#frmSearchLocation > table > tbody > tr:nth-child(5) td')

#page_section <- html_node(rawHTML, xpath = '//br+//table//td')

file <- html_text(page_section)

#one method to break up text into different cells
require(data.table)
o = fread(file, sep = '\n', header = T)

  #test 
  #o = c('zy', 'x    y', '')

#trim whitespace
o$`Search Results` = str_trim(o$`Search Results`)

#drop empty rows
drop_list = o$`Search Results`==""
o <- o[!drop_list, ]

#drop rows saying "Details..."
drop_list = o$`Search Results`== "Details..."
o <- o[!drop_list, ]

#some grant dates are in a 3-row format; merge when this is the case
  #e.g. 21
        #to
        #22
  # and not: 2023-24
o$merge_list = o$`Search Results`== "to"
  #sum(merge_list) #381
```

##CIHR datacleaning, pas complete

```{r}
library(tidyverse)

#flag consecutive rows which need merging
p = o %>% 
  mutate(merge_rows=
           ifelse(merge_list==T ,
              paste(row_number()-1, row_number()+1, sep = ":"),
              NA),
        merge_start =
           ifelse(merge_list==T,
              paste(row_number()-1)
              ,NA)
         ) %>% 
  filter(merge_list==T)

### not working
##as.data.frame(p)
o[p[[4]],]

paste(o[[p$merge_rows]]

  mutate(concated_column = o[merge_rows,])

rbind(p, row3 = apply(p, 2, paste0, collapse = "-"))
```

```{r}

input <- data_frame(text = file)
input

p_load(dplyr, lubridate)
df <- matrix(input, ncol = 7, byrow = TRUE) %>% 
  as_tibble() %>% 
  mutate(V1 = mdy(V1), V2 = as.numeric(V2))


data$text
data <-
  data %>% 
  separate(text, into = c("text1", "text2", "text3", "text4", "text5", 
                          "text6", "text7", "text8", "text9", "text10"), sep = "Back to text")
```
