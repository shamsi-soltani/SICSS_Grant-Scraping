---
title: "Projet SICCS Montreal 2023 de Shamsi Soltani"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  warning = TRUE, # show warnings
  message = TRUE, # show messages
  error = TRUE, # do not interrupt generation in case of errors,
  echo = TRUE  # show R code
)
library(pacman)
p_load(knitr, 
       tidyverse, tidytext, 
       textdata, tm, 
       maps, SnowballC, 
       wordcloud, topicmodels, repoRter.nih)

knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 60), tidy = TRUE)
```

*Run* = *Cmd+Shift+Enter*. *Insert Chunk* = *Cmd+Option+I*

#Use Reporter NIH package

##Testing package with small dataset
```{r}
#exploring repoRter.nih

#define fields you want 
data("nih_fields") 

fields <- nih_fields %>%
  filter(response_name %in% 
    c("appl_id", "terms", "activity_code", "project_title", "fiscal_year", "award_amount", "is_active", "project_start_date", "abstract_text","program_officers", "activity_type" #, "organization", "organization_type"
      )) %>% pull(include_name)


# req <- make_req(criteria = list(fiscal_years = 2013:2023 #more recent active awards will be included
#                                 #, include_active_projects = TRUE,
#                                 ),
#                 include_fields = fields, limit = 50, message = FALSE)
# grants %>% glimpse(width = getOption("cli.width"))


req <- make_req(criteria = list(advanced_text_search 
                    = list(operator = "advanced",
                    search_field = c("terms", "abstract", "projecttitle"),
                    search_text = "(suicide) OR \"self-directed violence\""),
             activity_codes = 'F31',
             fiscal_years = 2012:2023
             ),
      include_fields = fields )

grants <- get_nih_data(query = req, max_pages = 1, flatten_result=TRUE)
    #remove max pages once query final if seeking more than 500 recs

table(grants$activity_code) 
  #N=225 F31 funded apps in last decade with suicide or self-directed violence as a title, narrative, or key word; 340 total in database
```
##looking at small dataset using text analysis
```{r text processing}
# Create corpus
corpus = Corpus(VectorSource(grants$abstract_text))

#Conversion to Lowercase

corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, tolower)

#Removing Punctuation
corpus = tm_map(corpus, removePunctuation)

#Remove stopwords
corpus = tm_map(corpus, removeWords, c("project", "summary", stopwords("english")))

# Stemming
corpus = tm_map(corpus, stemDocument)

# Eliminate white spaces
corpus = tm_map(corpus, stripWhitespace)

# Look at first instance of corpus
corpus[[1]][1]

#Document term matrix
DTM <- TermDocumentMatrix(corpus)
mat <- as.matrix(DTM)
f <- sort(rowSums(mat),decreasing=TRUE)
dat <- data.frame(word = names(f),freq=f)

head(dat, 5)
```
##wordcloud
```{r wordcloud}
set.seed(100)
display.brewer.all(colorblindFriendly = TRUE)      # Show all color palettes

wordcloud(words = dat$word, freq = dat$freq, min.freq = 10,           max.words=500, random.order=F, scale=c(3,.25), rot.per=0.3
           , colors=brewer.pal(8, "Dark2"))

p_load(wordcloud2)
wordcloud2(dat,size = .8, minRotation = -pi/6, maxRotation = -pi/6, rotateRatio = 1)
```

##élargir la recherche à tous les fonds des NIH, parallèlement au code du CIHR 
(Voir "CIHR Data Import" de Leonard au GitHub)

CIHR fields include 
  abstract = Abstract.Résumé,
  key = Key.Clé,
  name = Name.Nom,
  organization = OrgNm,
  province = ProvinceEN,
  country = CountryEN,
  year_comp = CompetitionYear.AnnéeDuConcours,
  year_fisc = FiscalYear.AnnéeFinancière,
  programID = ProgramIDProgramme,
  program_name = ProgramNameEN,
  funding_type = FundingTypeEN,
  science_areas = AreasOfScienceEN,
  research_class = ResearchClassEN,
  title = TitreApplicationTitle,
  keywords = Keywords.MotsClés
```{r}

#define fields you want 
data("nih_fields") 

fields <- nih_fields %>%
  filter(response_name %in% 
    c("abstract_text", "project_serial_num", "contact_pi_name", "terms", "activity_code", "project_title", "fiscal_year", "award_amount", "is_active", "project_start_date", "activity_type", "agency_code", "agency_ic_fundings", "cong_district", "spending_categories_desc", "full_foa"
      )) %>% pull(include_name)
```
  abstract = "abstract_text",
  key =  "project_serial_num"
  name = "contact_pi_name", # possibly also "principal_investigators"
  organization = OrgNm,
  province = "cong_district",
  year_comp = "project_start_date",
  year_fisc = "fiscal_year",
  programID = ProgramIDProgramme,
  program_name = ProgramNameEN,
  funding_type = FundingTypeEN,
  science_areas = AreasOfScienceEN,
  research_class = ResearchClassEN,
  title = "project_title",
  keywords = "terms"
  
quels sont les mots qui indiquent les sciences sociales? J’ai: sociaux, sociales, qualitatives, qualitatif, qualitative, qualitatifs, sociale, social

en anglais: social, qualitative
```{r json}
#create json for NIH API
req <- make_req(criteria = list(advanced_text_search 
                    = list(operator = "advanced",
                    search_field = c("terms", "abstract", "projecttitle"),
                    search_text = "(social) OR (qualitative)"),
  fiscal_years = 2001:2023,
  activity_codes = c('F','R','K')
), 
      include_fields = fields )

grants <- get_nih_data(query = req, max_pages = 1, flatten_result=TRUE)
    #remove max pages once query final if seeking more than 500 recs; 

#grants <- get_nih_data(query = req, flatten_result=TRUE)

#Note: API request fails after 15,000 records


```
#CIHR data

##strategie pas au courant-- voir le GH
```{r}
p_load(tidyverse,magrittr,rvest)
#setwd('/Users/ssoltani/Desktop/PhD coursework/Cours_SICSS_Montreal/grant funding project')
rawHTML <- read_html("./00.Data/CIHR_suicide_research.html")

page_section <- html_node(rawHTML, css = '#frmSearchLocation > table > tbody > tr:nth-child(5) td')

#page_section <- html_node(rawHTML, xpath = '//br+//table//td')

file <- html_text(page_section)

#one method to break up text into different cells
require(data.table)
o = fread(file, sep = '\n', header = T)

  #test 
  #o = c('zy', 'x    y', '')

#trim whitespace
o$`Search Results` = str_trim(o$`Search Results`)

#drop empty rows
drop_list = o$`Search Results`==""
o <- o[!drop_list, ]

#drop rows saying "Details..."
drop_list = o$`Search Results`== "Details..."
o <- o[!drop_list, ]

#some grant dates are in a 3-row format; merge when this is the case
  #e.g. 21
        #to
        #22
  # and not: 2023-24
o$merge_list = o$`Search Results`== "to"
  #sum(merge_list) #381
```
##CIHR datacleaning, pas complete
```{r}
library(tidyverse)

#flag consecutive rows which need merging
p = o %>% 
  mutate(merge_rows=
           ifelse(merge_list==T ,
              paste(row_number()-1, row_number()+1, sep = ":"),
              NA),
        merge_start =
           ifelse(merge_list==T,
              paste(row_number()-1)
              ,NA)
         ) %>% 
  filter(merge_list==T)

### not working
##as.data.frame(p)
o[p[[4]],]

paste(o[[p$merge_rows]]

  mutate(concated_column = o[merge_rows,])

rbind(p, row3 = apply(p, 2, paste0, collapse = "-"))
```

```{r}

input <- data_frame(text = file)
input

p_load(dplyr, lubridate)
df <- matrix(input, ncol = 7, byrow = TRUE) %>% 
  as_tibble() %>% 
  mutate(V1 = mdy(V1), V2 = as.numeric(V2))


data$text
data <-
  data %>% 
  separate(text, into = c("text1", "text2", "text3", "text4", "text5", 
                          "text6", "text7", "text8", "text9", "text10"), sep = "Back to text")
```
